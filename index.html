<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FFT-MIL: Fourier Transform Multiple Instance Learning for Whole Slide Image Classification.">
  <meta name="keywords" content="Multiple Instance Learning, Whole Slide Image Classification, Fourier Transform, Medical Imaging, Computational Pathology, Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FFT-MIL: Fourier Transform Multiple Instance Learning for Whole Slide Image Classification</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FFT-MIL: Fourier Transform Multiple Instance Learning for Whole Slide Image Classification
</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://irulenot.github.io/">Anthony Bilic</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://guangyusun.com/">Guangyu Sun</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://liming-ai.github.io/">Ming Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.mdsanzidbinhossain.com/github/">Md Sanzid Bin Hossain</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://yutianyt.com/">Yu Tian</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.cs.ucf.edu/~wzhang/">Wei Zhang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://med.ucf.edu/person/laura-brattain-ph-d/">Laura Brattain</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=2o8ORCAAAAAJ&hl=en">Dexter Hadley</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.crcv.ucf.edu/chenchen/">Chen Chen</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute of Artificial Intelligence (IAI),</span>
            <span class="author-block"><sup>2</sup>Department of Computer Science,</span>
            <span class="author-block"><sup>3</sup>College of Medicine</span>
            <span class="author-block">University of Central Florida</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.15138"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/irulenot/FFT-MIL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="font-size: 16px; line-height: 1.7; color: #222; max-width: 800px; margin: auto;">
            <strong>Whole Slide Image (WSI) classification</strong> relies on 
            <strong>Multiple Instance Learning (MIL)</strong> with spatial patch features, yet existing methods 
            struggle to capture global dependencies due to the immense size of WSIs and the local nature of 
            patch embeddings. This limitation hinders the modeling of coarse structures essential for robust 
            diagnostic prediction. 
            <br><br>
            We propose <strong style="color:#003366;">Fourier Transform Multiple Instance Learning (FFT-MIL)</strong>, 
            a framework that augments MIL with a frequency-domain branch to provide compact global context. 
            Low-frequency crops are extracted from WSIs via the Fast Fourier Transform and processed through a 
            modular <strong style="color:#004c4c;">FFT-Block</strong> composed of convolutional layers and 
            Min-Max normalization to mitigate the high variance of frequency data. The learned global frequency 
            feature is fused with spatial patch features through lightweight integration strategies, enabling 
            compatibility with diverse MIL architectures. 
            <br><br>
            FFT-MIL was evaluated across six state-of-the-art MIL methods on three public datasets 
            (<strong>BRACS</strong>, <strong>LUAD</strong>, and <strong>IMP</strong>). Integration of the FFT-Block 
            improved macro F1 scores by an average of <strong>3.51%</strong> and AUC by <strong>1.51%</strong>, 
            demonstrating consistent gains across architectures and datasets. These results establish 
            frequency-domain learning as an effective and efficient mechanism for capturing global dependencies 
            in WSI classification, complementing spatial features and advancing the scalability and accuracy of 
            MIL-based computational pathology.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  <!-- Shared image style -->
  <style>
    .paper-figure {
      max-width: 100%;
      width: 900px; /* fixed visual width for consistency */
      border-radius: 8px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
    }

    @media (max-width: 1024px) {
      .paper-figure {
        width: 100%; /* responsive scaling on smaller screens */
      }
    }
  </style>

  <!-- Paper architecture. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Architecture</h2>

      <!-- Architecture Image -->
      <a href="static/images/architecture.jpg" target="_blank">
        <img src="static/images/architecture.jpg" alt="FFT-MIL Architecture" class="paper-figure">
      </a>

      <!-- Description -->
      <div style="text-align: left; font-size: 16px; line-height: 1.7; color: #333; margin-top: 1.2em; max-width: 700px; margin-left: auto; margin-right: auto;">
        The proposed <strong style="color:#003366;">Fourier Transform Multiple Instance Learning (FFT-MIL)</strong> framework 
        augments existing MIL methods with a <strong>frequency-domain branch</strong> to improve global context modeling 
        in WSI classification. The <strong style="color:#004c4c;">FFT-Block</strong> extracts a global frequency feature 
        from a given WSI, which is fused with the output of CLAM’s attention backbone via addition to introduce global 
        context at a stage where patch-level information has been aggregated. While illustrated with CLAM, the 
        <strong>FFT-Block</strong> is modular and can be integrated into other MIL methods in a similar fashion.
      </div>
    </div>
  </div>
  <!--/ Paper architecture. -->

  <!-- Paper preprocessing. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Preprocessing</h2>

      <!-- Preprocessing Image -->
      <a href="static/images/preprocessing.jpg" target="_blank">
        <img src="static/images/preprocessing.jpg" alt="FFT-MIL Preprocessing" class="paper-figure">
      </a>

      <!-- Description -->
      <div style="text-align: left; font-size: 16px; line-height: 1.7; color: #333; margin-top: 1.2em; max-width: 700px; margin-left: auto; margin-right: auto;">
        The preprocessing pipeline generates <strong style="color:#003366;">low-frequency representations</strong> of whole slide images (WSIs) to provide compact global context for downstream analysis. 
        A tissue segmentation branch first identifies relevant regions at low magnification for efficient patch extraction, while the <strong style="color:#004c4c;">FFT-MIL branch</strong> operates on a downsampled WSI to apply the Fast Fourier Transform, frequency shifting, and center cropping. 
        This process retains the dominant low-frequency components that capture large-scale structural patterns while filtering out high-frequency noise. 
        A reconstruction pathway is included for visualization, highlighting how the extracted frequency information preserves global structure and diagnostic features with far lower input resolution.
      </div>
    </div>
  </div>
  <!--/ Paper preprocessing. -->

<!-- Paper results. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Results</h2>

    <!-- Results Image -->
    <a href="static/images/results.jpg" target="_blank">
      <img src="static/images/results.jpg" alt="FFT-MIL Results" class="paper-figure">
    </a>

    <!-- Description -->
    <div style="text-align: left; font-size: 16px; line-height: 1.7; color: #333; margin-top: 1.2em; max-width: 700px; margin-left: auto; margin-right: auto;">
      <strong style="color:#003366;">FFT-MIL</strong> consistently improves the performance of existing Multiple Instance Learning (MIL) methods 
      by integrating <strong>frequency-derived global features</strong> with traditional spatial representations. 
      The framework was evaluated across six MIL architectures, including CLAM, MIL, ABMIL, ACMIL, IBMIL, and ILRA, 
      on the <strong>BRACS</strong>, <strong>LUAD</strong>, and <strong>IMP</strong> datasets. 
      FFT-MIL increased the average performance by <strong style="color:#004c4c;">3.51%</strong> in F1 score and 
      <strong style="color:#004c4c;">1.51%</strong> in AUC. 
      These improvements demonstrate its effectiveness as a general plug-in mechanism for enhancing diagnostic accuracy 
      in whole slide image classification.
    </div>
  </div>
</div>

<!-- Paper heatmaps. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Attention Heatmap</h2>

    <!-- Heatmaps Image -->
    <a href="static/images/heatmaps.jpg" target="_blank">
      <img src="static/images/heatmaps.jpg" alt="FFT-MIL Attention Heatmaps" class="paper-figure">
    </a>

    <!-- Description -->
    <div style="text-align: left; font-size: 16px; line-height: 1.7; color: #333; margin-top: 1.2em; max-width: 700px; margin-left: auto; margin-right: auto;">
      The heatmaps illustrate the spatial impact of <strong style="color:#003366;">frequency-domain integration</strong> on attention behavior in WSI classification. 
      Attention maps from the baseline CLAM model and the proposed <strong style="color:#004c4c;">FFT-MIL</strong> framework are compared on a representative BRACS slide. 
      Both highlight similar diagnostic regions, while a pixel-wise difference map identifies areas of divergence. 
      The baseline CLAM shows more diffuse attention, which indicates limited spatial precision and weaker global context. 
      FFT-MIL produces sharper and more selective focus regions, supported by a <strong>16% reduction in entropy</strong> 
      and a <strong>23% increase in standard deviation</strong>, which reflect improved concentration of attention. 
      These findings show that FFT-MIL maintains alignment with the main semantic regions identified by CLAM while achieving greater spatial selectivity 
      and precision in its attention distributions.
    </div>
  </div>
</div>
<!--/ Paper heatmaps. -->


</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@misc{bilic2025fouriertransformmultipleinstance,
  title={Fourier Transform Multiple Instance Learning for Whole Slide Image Classification},
  author={Anthony Bilic and Guangyu Sun and Ming Li and Md Sanzid Bin Hossain and Yu Tian and Wei Zhang and Laura Brattain and Dexter Hadley and Chen Chen},
  year={2025},
  eprint={2510.15138},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2510.15138}
}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
